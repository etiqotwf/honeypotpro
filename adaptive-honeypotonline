// dqn-honeypot-ai-hf.js
// Combined DQN honeypot + Hugging Face LLM integration (flexible: classification or generation)
// All LLM outputs are requested in English.
// Usage: set .env with HUGGINGFACE_API_KEY and HUGGINGFACE_MODEL (e.g. facebook/bart-large-mnli)

import * as tf from '@tensorflow/tfjs';
// For better Node performance install: npm i @tensorflow/tfjs-node
// and replace the above import with: import '@tensorflow/tfjs-node';

import fs from 'fs';
import path from 'path';
import readline from 'readline';
import { fileURLToPath } from 'url';
import chalk from 'chalk';
import figlet from 'figlet';
import gradient from 'gradient-string';
import boxen from 'boxen';
import fetch from 'node-fetch';
import dotenv from 'dotenv';

dotenv.config();

// Resolve __dirname in ESM
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// Paths
const INPUT_PUBLIC_CSV = path.join(__dirname, 'public', 'logs', 'threats.csv'); // source data (public)
const OUTPUT_PROJECT_CSV = path.join(__dirname, 'logs', 'threats.csv');       // where results are saved (project logs)
const REPLAY_FILE = path.join(__dirname, 'logs', 'replay.json');             // replay memory
const MODEL_FILE = path.join(__dirname, 'model.json');
const WEIGHTS_FILE = path.join(__dirname, 'weights.bin');

// Actions and hyperparameters
const ACTIONS = ['block', 'alert', 'ignore'];
const LEARNING_RATE = 0.01;
const EPOCHS = 50;
const FINETUNE_EPOCHS = 5;
const BATCH_LIMIT = 2000;

let model;

// Hugging Face configuration via environment
const HUGGINGFACE_API_KEY = process.env.HUGGINGFACE_API_KEY || '';
const HUGGINGFACE_MODEL = process.env.HUGGINGFACE_MODEL || 'mistralai/Mistral-7B-Instruct-v0.2';
const HUGGINGFACE_ENDPOINT = `https://api-inference.huggingface.co/models/${encodeURIComponent(HUGGINGFACE_MODEL)}`;

/* ---------- UI banner ---------- */
function welcomeBanner() {
  // ❌ احذف console.clear(); أو علّقها
  // console.clear();

  const title = figlet.textSync('DQN Honeypot', { horizontalLayout: 'full' });
  const banner = boxen(gradient.pastel.multiline(title), { padding: 1, margin: 1, borderStyle: 'round' });
  console.log(banner);
}


/* ---------- Encoding / heuristics ---------- */
function encodeStateFromString(logLine) {
  const ipSuspicion = logLine.includes('192.168') ? 0 : 1;
  const requestType = logLine.includes('POST') ? 1 : 0;
  const keywordDetected = /(malware|attack|scan)/i.test(logLine) ? 1 : 0;
  return [ipSuspicion, requestType, keywordDetected, 0, 0, 0, 0, 0];
}

function encodeStateFromRecord({ ip = '', method = '', threatType = '' }) {
  const ipSuspicion = ip.startsWith('192.168.') ? 0 : 1;
  const requestType = method === 'POST' ? 1 : 0;
  const keywordDetected = /(malware|attack|scan)/i.test(threatType) ? 1 : 0;
  return [ipSuspicion, requestType, keywordDetected, 0, 0, 0, 0, 0];
}

function inferLabelHeuristic(logLine) {
  if (/(malware|attack|scan)/i.test(logLine)) return 'block';
  if (/POST/i.test(logLine)) return 'alert';
  return 'ignore';
}

function encodeAction(action) {
  return ACTIONS.map(a => (a === action ? 1 : 0));
}

/* ---------- Model create / save / load ---------- */
function createModel() {
  const m = tf.sequential();
  m.add(tf.layers.dense({ units: 64, inputShape: [8], activation: 'relu' }));
  m.add(tf.layers.dense({ units: 64, activation: 'relu' }));
  m.add(tf.layers.dense({ units: ACTIONS.length, activation: 'softmax' }));
  m.compile({ optimizer: tf.train.adam(LEARNING_RATE), loss: 'categoricalCrossentropy' });
  return m;
}

async function saveModelDisk(m) {
  const artifacts = await m.save(tf.io.withSaveHandler(async (artifacts) => artifacts));
  fs.writeFileSync(MODEL_FILE, JSON.stringify({ modelTopology: artifacts.modelTopology, weightSpecs: artifacts.weightSpecs }), 'utf8');
  fs.writeFileSync(WEIGHTS_FILE, Buffer.from(artifacts.weightData));
  console.log(chalk.greenBright('✅ Model saved to disk.'));
}

async function loadOrInitModel() {
  if (fs.existsSync(MODEL_FILE) && fs.existsSync(WEIGHTS_FILE)) {
    try {
      const modelData = JSON.parse(fs.readFileSync(MODEL_FILE, 'utf8'));
      const weightData = fs.readFileSync(WEIGHTS_FILE);
      const artifacts = {
        modelTopology: modelData.modelTopology,
        weightSpecs: modelData.weightSpecs,
        weightData: new Uint8Array(weightData).buffer
      };
      model = await tf.loadLayersModel(tf.io.fromMemory(artifacts));
      model.compile({ optimizer: tf.train.adam(LEARNING_RATE), loss: 'categoricalCrossentropy' });
      console.log(chalk.green('📦 Model loaded and compiled.'));
      return;
    } catch (err) {
      console.log(chalk.yellow('⚠️ Failed to load model from disk, will re-initialize. Error:'), err.message);
    }
  }

  model = createModel();
  console.log(chalk.cyan('🧪 No saved model found — bootstrap training...'));

  const bootstrap = [
    { ip: '192.168.0.2', method: 'POST', threatType: 'malware detected' },
    { ip: '10.0.0.5', method: 'GET', threatType: 'normal traffic' },
    { ip: '172.16.0.1', method: 'POST', threatType: 'scan attempt' },
    { ip: '8.8.8.8', method: 'GET', threatType: 'attack vector' },
  ];

  const data = bootstrap.map(r => ({ state: encodeStateFromRecord(r), action: inferLabelHeuristic(`${r.method} ${r.threatType}`) }));
  await trainModel(data, EPOCHS);
}

async function trainModel(pairs, epochs = EPOCHS) {
  if (!pairs || pairs.length === 0) return;
  const xs = tf.tensor2d(pairs.map(p => p.state));
  const ys = tf.tensor2d(pairs.map(p => encodeAction(p.action)));
  console.log(chalk.cyan(`🔧 Training on ${pairs.length} samples for ${epochs} epochs...`));
  await model.fit(xs, ys, {
    epochs,
    shuffle: true,
    callbacks: {
      onEpochEnd: (epoch, logs) => console.log(chalk.gray(`Epoch ${epoch + 1}: loss=${(logs.loss || 0).toFixed(6)}`))
    }
  });
  await saveModelDisk(model);
  xs.dispose();
  ys.dispose();
}

/* ---------- Inference ---------- */
async function selectAction(state) {
  const input = tf.tensor2d([state]);
  const pred = model.predict(input);
  const idx = (await pred.argMax(-1).data())[0];
  input.dispose();
  if (pred.dispose) pred.dispose();
  return ACTIONS[idx];
}

/* ---------- CSV reading / processing ---------- */
function readPublicCsv() {
  if (!fs.existsSync(INPUT_PUBLIC_CSV)) return [];
  const text = fs.readFileSync(INPUT_PUBLIC_CSV, 'utf8').trim();
  if (!text) return [];
  const lines = text.split(/\r?\n/);
  // assume header in first line
  const header = lines.shift();
  if (!lines.length) return [];
  return lines
    .filter(Boolean)
    .map(line => {
      const parts = line.split(',');
      const timestamp = (parts[0] || '').trim() || new Date().toISOString();
      const ip = (parts[1] || '').trim();
      const method = (parts[2] || '').trim();
      const threatType = (parts.slice(3).join(',') || '').trim() || 'unknown';
      return { timestamp, ip, method, threatType };
    })
    .filter(r => r.ip && r.method);
}

function loadAlreadyProcessedKeys() {
  if (!fs.existsSync(OUTPUT_PROJECT_CSV)) return new Set();
  const text = fs.readFileSync(OUTPUT_PROJECT_CSV, 'utf8').trim();
  if (!text) return new Set();
  const lines = text.split(/\r?\n/);
  lines.shift(); // header
  const set = new Set();
  for (const ln of lines) {
    if (!ln) continue;
    const parts = ln.split(',');
    const ip = (parts[1] || '').trim();
    const method = (parts[2] || '').trim();
    const threatType = (parts[3] || '').trim();
    set.add(`${ip}|${method}|${threatType}`);
  }
  return set;
}

function loadReplayMemory() {
  try {
    if (!fs.existsSync(REPLAY_FILE)) return [];
    const arr = JSON.parse(fs.readFileSync(REPLAY_FILE, 'utf8'));
    return Array.isArray(arr) ? arr : [];
  } catch {
    return [];
  }
}

function saveReplayMemory(mem) {
  const trimmed = mem.slice(-BATCH_LIMIT);
  fs.writeFileSync(REPLAY_FILE, JSON.stringify(trimmed, null, 2), 'utf8');
}

function ensureOutputHeader() {
  const dir = path.join(__dirname, 'logs');
  if (!fs.existsSync(dir)) fs.mkdirSync(dir, { recursive: true });
  if (!fs.existsSync(OUTPUT_PROJECT_CSV)) {
    fs.writeFileSync(OUTPUT_PROJECT_CSV, 'Timestamp,IP,Method,ThreatType,Action\n', 'utf8');
  } else {
    // ensure Action column exists
    const content = fs.readFileSync(OUTPUT_PROJECT_CSV, 'utf8');
    const lines = content.split(/\r?\n/);
    if (lines.length && !lines[0].includes('Action')) {
      lines[0] = 'Timestamp,IP,Method,ThreatType,Action';
      fs.writeFileSync(OUTPUT_PROJECT_CSV, lines.join('\n') + '\n', 'utf8');
    }
  }
}

/* ---------- LLM (Hugging Face) Integration (flexible: classification or generation) ---------- */
async function analyzeThreatWithHF(logRecord) {
  if (!HUGGINGFACE_API_KEY) {
    return { type: 'Other', severity: 'unknown', summary: 'No HUGGINGFACE_API_KEY provided' };
  }

  // Candidate labels we want the classifier to choose from
  const CANDIDATE_LABELS = ["SQL Injection", "XSS", "LFI", "RCE", "Brute Force", "Scan", "Recon", "Other"];

  // Build a short plain text representation of the record
  const recordText = `IP: ${logRecord.ip}\nMethod: ${logRecord.method}\nThreatType: ${logRecord.threatType}`;

  try {
    // Detect whether we should call classification or generation:
    // if model name contains "mnli" or "zero-shot" or "bart" -> classification
    const modelLower = (HUGGINGFACE_MODEL || '').toLowerCase();
    const useClassification = modelLower.includes('mnli') || modelLower.includes('zero-shot') || modelLower.includes('bart') || modelLower.includes('classifier') || modelLower.includes('classification');

    let body;
    if (useClassification) {
      // zero-shot/classification payload
      body = {
        inputs: recordText,
        parameters: {
          candidate_labels: CANDIDATE_LABELS
        }
      };
    } else {
      // generation payload (text-generation)
      const prompt = `
You are a cybersecurity analyst assistant. Given the HTTP record below, classify the attack type, estimate severity, and provide a one-line English summary.
Return ONLY valid JSON with keys: type, severity, summary.

Record:
${recordText}

Example: {"type":"SQL Injection","severity":"high","summary":"Attempt to inject SQL via login parameter"}
`.trim();

      body = {
        inputs: prompt,
        parameters: {
          max_new_tokens: 200,
          temperature: 0.2,
          top_p: 0.9,
          repetition_penalty: 1.02
        }
      };
    }

    const res = await fetch(HUGGINGFACE_ENDPOINT, {
  method: 'POST',
  headers: {
    'Authorization': `Bearer ${HUGGINGFACE_API_KEY}`,
    'Content-Type': 'application/json'
  },
  body: JSON.stringify({
    ...body,
    options: { wait_for_model: true, use_cache: false }
  })
});


    // If non-JSON returned (e.g., "Not Found") this will throw or produce text
    const json = await res.json().catch(async () => {
      const txt = await res.text();
      throw new Error(`HF raw response: ${txt}`);
    });

    // ----- Handle classification response shapes -----
    // Many classification endpoints return either:
    // { labels: [...], scores: [...] }  OR  [{ labels: [...], scores: [...] }]
    if (useClassification) {
      let labels = null;
      let scores = null;

      if (Array.isArray(json) && json[0]) {
        labels = json[0].labels || json[0].label || null;
        scores = json[0].scores || json[0].score || null;
      } else if (typeof json === 'object' && json !== null) {
        labels = json.labels || json.label || null;
        scores = json.scores || json.score || null;
      }

      // Some endpoints return single label in 'label' and 'score'
      if (!labels && json.hasOwnProperty('label') && json.hasOwnProperty('score')) {
        labels = [json.label];
        scores = [json.score];
      }

      if (Array.isArray(labels) && labels.length > 0) {
        const topLabel = labels[0];
        const topScore = Array.isArray(scores) && scores[0] ? scores[0] : null;

        // Map confidence to severity heuristically
        let severity = 'low';
        if (typeof topScore === 'number') {
          if (topScore >= 0.85) severity = 'high';
          else if (topScore >= 0.6) severity = 'medium';
        } else {
          severity = 'unknown';
        }

        const summary = `Predicted label: ${topLabel}${topScore ? ` (score=${(topScore).toFixed(3)})` : ''}`;
        console.log(chalk.green('✅ HF classification response parsed.'));
        return { type: topLabel || 'Other', severity, summary };
      }

      // fallback if shape unexpected
      console.warn(chalk.yellow('⚠️ Unexpected classification response shape from HF, falling back to raw output.'));
      return { type: 'Other', severity: 'unknown', summary: JSON.stringify(json).slice(0, 200) };
    }

    // ----- Handle generation response shapes -----
    // Many generation endpoints return: [{ generated_text: "..." }] or { generated_text: "..." }
    let textOutput = '';
    if (Array.isArray(json) && json.length > 0 && json[0].generated_text) {
      textOutput = json[0].generated_text;
    } else if (typeof json === 'object' && json.generated_text) {
      textOutput = json.generated_text;
    } else if (typeof json === 'string') {
      textOutput = json;
    } else {
      textOutput = JSON.stringify(json);
    }

    // try extract JSON object from generation output
    const jsonMatch = textOutput.match(/\{[\s\S]*\}/m);
    if (jsonMatch) {
      try {
        const parsed = JSON.parse(jsonMatch[0]);
        console.log(chalk.green('✅ LLM generation returned JSON and was parsed.'));
        return {
          type: parsed.type || 'Other',
          severity: (parsed.severity || 'unknown').toLowerCase(),
          summary: parsed.summary || ''
        };
      } catch (e) {
        // not valid JSON inside generated text
      }
    }

    // If no JSON, attempt a simple heuristic: look for keywords to map to types
    const lowered = textOutput.toLowerCase();
    const keywordMap = [
      { k: 'sql', t: 'SQL Injection' },
      { k: 'xss', t: 'XSS' },
      { k: 'local file', t: 'LFI' },
      { k: 'rce', t: 'RCE' },
      { k: 'brute', t: 'Brute Force' },
      { k: 'scan', t: 'Scan' },
      { k: 'recon', t: 'Recon' }
    ];
    for (const km of keywordMap) {
      if (lowered.includes(km.k)) {
        console.log(chalk.green('✅ LLM generation heuristic matched keyword:', km.k));
        return { type: km.t, severity: 'medium', summary: textOutput.trim().slice(0, 200) };
      }
    }

    // final fallback: return raw trimmed text as summary
    return { type: 'Other', severity: 'unknown', summary: textOutput.trim().slice(0, 200) };

  } catch (err) {
    console.error(chalk.red('HF analysis error:'), err.message);
    return { type: 'Other', severity: 'unknown', summary: 'HF analysis failed' };
  }
}





/* ---------- Inference helpers ---------- */
async function selectActionWithLLMHint(state, llmResult) {
  // Default: use model decision
  let action = await selectAction(state);

  // If LLM says severity high, prefer blocking
  if (llmResult && llmResult.severity === 'high') {
    action = 'block';
  } else if (llmResult && llmResult.severity === 'medium' && action === 'ignore') {
    // escalate ignore -> alert if LLM suggests medium severity
    action = 'alert';
  }

  return action;
}

/* ---------- Processing last public record ---------- */
async function processLastPublicRecord() {
  const records = readPublicCsv();
  if (!records.length) {
    console.log(chalk.yellow('ℹ️ No records found in public/logs/threats.csv to process.'));
    return;
  }

  const lastRecord = records[records.length - 1];
  const processedKeys = loadAlreadyProcessedKeys();
  const key = `${lastRecord.ip}|${lastRecord.method}|${lastRecord.threatType}`;

  if (processedKeys.has(key)) {
    console.log(chalk.gray('ℹ️ The last entry has already been processed.'));
    return;
  }

  const state = encodeStateFromRecord(lastRecord);

  // LLM analysis (English output via Hugging Face)
  const llmResult = await analyzeThreatWithHF(lastRecord);
  console.log(chalk.blue(`🤖 LLM: type=${llmResult.type}, severity=${llmResult.severity}, summary=${llmResult.summary}`));

  // Select action using DQN model with optional LLM hint
  const action = await selectActionWithLLMHint(state, llmResult);

  // Log the result to project CSV
  // logThreat function is expected to exist in ./logThreats.js and accept (ip, method, threatType, action, timestamp)
  try {
    // Keep compatibility with existing logThreat implementation
    const { logThreat } = await import('./logThreats.js');
    logThreat(lastRecord.ip, lastRecord.method, lastRecord.threatType, action, lastRecord.timestamp);
  } catch (e) {
    // Fallback: append to OUTPUT_PROJECT_CSV directly if logThreat import fails
    const row = `${lastRecord.timestamp},${lastRecord.ip},${lastRecord.method},${lastRecord.threatType},${action}\n`;
    fs.appendFileSync(OUTPUT_PROJECT_CSV, row, 'utf8');
  }

  console.log(chalk.greenBright(`✅ Processed last entry: ${lastRecord.ip} ${lastRecord.method} ${lastRecord.threatType} -> ${action}`));

  const replay = loadReplayMemory();
  replay.push({ state, action });
  saveReplayMemory(replay);
  console.log(chalk.cyan('⚙️ Fine-tuning on latest replay...'));
  await trainModel(replay, FINETUNE_EPOCHS);
  console.log(chalk.green('🧠 Fine-tune complete.'));
}

/* ---------- Backward compatibility: process local honeypot.log ---------- */
function ensureHoneypotLogExists() {
  const logPath = path.join(__dirname, 'logs');
  const logFile = path.join(logPath, 'honeypot.log');
  if (!fs.existsSync(logPath)) fs.mkdirSync(logPath, { recursive: true });
  if (!fs.existsSync(logFile)) {
    fs.writeFileSync(logFile, [
      "192.168.0.2 POST malware detected",
      "10.0.0.5 GET normal traffic",
      "172.16.0.1 POST scan attempt",
      "8.8.8.8 GET attack vector"
    ].join('\n'), 'utf8');
  }
  return logFile;
}

async function processHoneypotLog(logFile) {
  const rl = readline.createInterface({ input: fs.createReadStream(logFile), crlfDelay: Infinity });
  for await (const line of rl) {
    if (!line.trim()) continue;
    const state = encodeStateFromString(line);
    const action = await selectAction(state);

    const parts = line.split(' ');
    const ip = parts[0] || '0.0.0.0';
    const method = parts[1] || 'GET';
    const threatType = parts.slice(2).join(' ') || 'unknown';

    try {
      const { logThreat } = await import('./logThreats.js');
      logThreat(ip, method, threatType, action, new Date().toISOString());
    } catch (e) {
      const row = `${new Date().toISOString()},${ip},${method},${threatType},${action}\n`;
      fs.appendFileSync(OUTPUT_PROJECT_CSV, row, 'utf8');
    }

    console.log(chalk.gray(`Processed honeypot.log: ${ip} ${method} ${threatType} -> ${action}`));
  }
}

/* ---------- Main ---------- */
  (async () => {

  welcomeBanner();
console.log(chalk.gray('──────────────────────────────────────────────'));

  // Print LLM configuration status
  if (HUGGINGFACE_API_KEY) {
    console.log(chalk.magentaBright(`🤖 Using Hugging Face model: ${HUGGINGFACE_MODEL} (LLM mode active)`));
  } else {
    console.log(chalk.redBright('⚠️ No HUGGINGFACE_API_KEY detected — LLM analysis will be skipped.'));
  }

  // Initial connection test to Hugging Face and heartbeat setup
  if (HUGGINGFACE_API_KEY) {
    console.log(chalk.gray('🌐 Checking connection to Hugging Face API...'));
    try {
      const testResponse = await fetch(HUGGINGFACE_ENDPOINT, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${HUGGINGFACE_API_KEY}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          inputs: "Connection test from DQN Honeypot AI",
          parameters: { max_new_tokens: 5 }
        })
      });

      if (testResponse.ok) {
        // try to parse but ignore content; presence of ok is good
        try { await testResponse.json(); } catch {}
        console.log(chalk.greenBright('✅ Connection to Hugging Face successful. LLM is ready.'));
      } else {
        console.log(chalk.redBright(`⚠️ Hugging Face API responded with status: ${testResponse.status}`));
      }
    } catch (err) {
      console.log(chalk.redBright(`❌ Failed to reach Hugging Face API: ${err.message}`));
    }

    // Heartbeat: check LLM every 60 seconds
    setInterval(async () => {
      try {
        const heartbeatResponse = await fetch(HUGGINGFACE_ENDPOINT, {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${HUGGINGFACE_API_KEY}`,
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({
            inputs: "ping",
            parameters: { max_new_tokens: 1 }
          })
        });

        if (heartbeatResponse.ok) {
          process.stdout.write(chalk.greenBright("💚 [LLM OK] "));
        } else {
          process.stdout.write(chalk.yellowBright(`💛 [LLM Warning: ${heartbeatResponse.status}] `));
        }
      } catch (error) {
        process.stdout.write(chalk.redBright(`💔 [LLM Disconnected: ${error.message}] `));
      }
    }, 60000); // every 60 seconds
  }

  ensureOutputHeader();
  await loadOrInitModel();

  // Process last record from public/logs/threats.csv now
  await processLastPublicRecord();

  // optional: process local honeypot.log (back-compat)
  // const hf = ensureHoneypotLogExists();
  // await processHoneypotLog(hf);

  // Watcher to re-process when CSV changes (debounced)
  if (fs.existsSync(INPUT_PUBLIC_CSV)) {
    let timer = null;
    fs.watch(INPUT_PUBLIC_CSV, (eventType) => {
      if (eventType) {
        if (timer) clearTimeout(timer);
        timer = setTimeout(async () => {
          console.log(chalk.cyan('🔁 Detected change in public/logs/threats.csv — processing latest entry...'));
          try {
            await processLastPublicRecord();
          } catch (err) {
            console.error('Error processing updated CSV:', err);
          }
        }, 500);
      }
    });
    console.log(chalk.gray('👁️ Watching public/logs/threats.csv for changes...'));
  } else {
    console.log(chalk.yellow('⚠️ No public/logs/threats.csv — copy it to the expected path to start processing.'));
  }
})();
